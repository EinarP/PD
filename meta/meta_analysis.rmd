---
title: "Wholistic Data Analysis Support Tool"
output:
  html_document:
    fig_height: 8
    fig_width: 10
    highlight: tango
    theme: journal
  word_document:
    fig_height: 10
    fig_width: 8
    highlight: tango
---
This document describes a tool for supporting the wholistic data analysis (explained in more detail elsewhere (*TODO: link*)) process. The essence of wholistic analysis is answering the research question (making inferences) by the sequence of wholeness-extending  transformations. Such analysis process would benefit enourmously from the availability of a support tool, due to huge amount of computation. The ecosystem for conducting analyses with the tool is described below first and then the implemented transformations

# The Analysis Ecosystem
Analysis ecosystem consists of observations and from a collection of R functions (currently all in one file):

```{r echo = FALSE}
suppressWarnings(suppressPackageStartupMessages(library(knitr)))
```
```{r}
# TODO: Split to multiple files and package
source('../wda.R')
```

Conduction of the analyses is illustrated by the tool usage meta-analysis

## Observations
Analyses are based on observations. These can be in a very universal manner presented as in the table below:

```{r echo = FALSE}
tbl <- matrix(c('Object', "Things (nested hierarchy levels separated by '>') or links (entities separated by '|') between them", 'OBSERVATION>property, VERTEX>id|OBSERVATION'), nrow = 1) %>%
  rbind(c('Property', 'Value or meta-characteristic', 'value, type, mandatory')) %>%
  rbind(c('Value', 'Property value', '10, numeric, TRUE')) %>%
  rbind(c('Instance', 'Id of an instance, if concrete cases have to be used (optional)', '123456789, LD1601300002')) %>%
  rbind(c('Checkpoint', 'Notional or temporal event of measuring (optional)', 'DISBURSEMENT, 2018-03-03T09:57:10')) %>%
  rbind(c('Source', 'Where the observation came from (optional)', 'gl, url, book reference'))

colnames(tbl) <- c('Element', 'Definition', 'Examples')

kable(tbl)
```

Compact presentation might be handy as well:

*checkpoint:levelx>group>entity>attribute>property=value{source}*

Observations can be assigned to a variable (like in a code snippet below) and/or added directly during any transformation

*TODO: Generate meta-data based on analysis object definition?*

```{r}
# Load observations for the analysis from a spreadsheet
suppressWarnings(library(readxl))
anobs <- read_excel('../data/meta.xlsx')

# Structure of sample observations
str(anobs)

# Summary of properties
table(anobs$property)

# Initialize the meta-analysis sequence
meta <- analysis('Meta-analysis', obs = 'anobs')

# Generate the structure
(meta <- grow(meta, 'OBSERVATION', attrs = TRUE, depth = 0))
```

## Sequence
Progression of the analysis has a certain structure. Simple chain of incremental steps is preferable, but trees, cirles, loops, etc. are possible as well. Each step  corresponds to a most appropriate (wholeness-extending) transformation

Starts with *analysis* and ends with *signoff*

```{r}
# Polish the output with appropriate seed and partitioning
meta <- grow(meta, 'SEQUENCE', depth = 2) %>% applySeed(417) %>% applyPartitioning('mbrp')
```

Checkpoint and instance later:

```{r}
summary(meta)

meta
```

## Structural component

Something about detailed view

* TODO: As similar to UML class digram as possible (except attributes separately)?*

```{r}
# Rearrange the structure
meta <- grow(meta, 'GRAPH', depth=2, attrs=TRUE, vals=TRUE)
meta <- void(meta, c('INFERENCE'))

# Polish the output with appropriate seed 
meta <- applySeed(meta, seed = 725)
meta
```

# Transformations

*TODO: Summary table*

Structure Generation
Essential Global Properties
Optional Global Properties
Creating order
Local Properties

### Center
```{r}
# Source data (observations)
sdata <- browseData(meta)
sdata[sdata$objsrc=='EDGE', ]

# Structure elements (target data)
tdata <- getElements(meta)
tdata[tdata$name=='EDGE', ]

tdata <- getRelations(meta)
tdata[grepl('EDGE', tdata$name), ]

```

### Grouping
```{r}
# Group GRAPH optional attributes
gmbr <- paste0('GRAPH>', c('sizing', 'sizing2', 'checkpoint',
  'partitioning', 'partitioning2', 'alternation', 'simplicity'))
gmeta <- group(meta, 'GRAPH>optional', gmbr)

# Group VERTEX optional attributes
gmbr <- paste0('VERTEX>', c('size',
  'size2', 'membership', 'membership2', 'contrast'))
gmeta <- group(gmeta, 'VERTEX>optional', gmbr)

# Group EDGE optional attributes
gmbr <- paste0('EDGE>', c('label', 'contrast'))
gmeta <- group(gmeta, 'EDGE>optional', gmbr)

# Apply appropriate seed and autoprint
gmeta <- applySeed(gmeta, 181)
gmeta

```

# Embedding
```{r}
# Identify key steps
summary(gmeta)

# Finalize the grouping branch
sqmain <- c('context', 'details', 'grouping')
signoff(gmeta, thumb_seq=c(4, 7, 11), thumb_narr=sqmain)
```

# Essential properties

### Randomization

```{r}
# Check for appropriate seed
browseSeeds(meta)

# Apply not so good seed
meta <- applySeed(meta, 527)
meta

# Current randomization settings
getSeed(meta)

```

## Layout
```{r}
# Check for appropriate layout (without partitioning as not always supported)
meta <- removePartitioning(meta)
browseLayouts(meta, plot=FALSE)
browseLayouts(meta)

# Apply an alternative layout
meta <- applyLayout(sq=meta, layout='layout_with_kk')
meta

# Current layout
getLayout(meta)
```

## Theme
```{r}
# Check for available themes
browseThemes(meta)

# Try minimalist theme without adding to sequence
applyTheme(meta, 'minimalist')

# Current theme
getTheme(meta)
```

# Optional properties

## Partitioning
```{r}
# Check clustering algorithms
browsePartitionings(meta, plot=FALSE)
browsePartitionings(meta)

# Visualize pregiven communities 
browseEntities(meta)[ ,c('object', 'mbrp')]

# Use pregiven partitioning instead
meta <- applyPartitioning(meta, 'mbrp')
meta

# Add secondary partitioning
meta <- applyPartitioning2(meta, 'tool_support')
meta

# Current partitioning
getPartitionings(meta)

```

## Sizing

```{r}
# Function for size calculation
psz <- function(ang) {
  power_centrality(ang)
}

# Sizes calculated by custom function
psz(meta[[length(meta)]])

# Test sizes calculated by the function
applySizing(meta, 'psz')

# Pregiven sizes
browseEntities(meta)[ ,c('object', 'wt')]

# Apply pregiven sizes
meta <- applySizing(meta, 'wt')
meta

# Current sizing
getSizing(meta)
```

## Alternation
```{r}
# Apply alternation
meta <- applyAlternation(meta)
meta

# Current alternation
getAlternation(meta)

# Remove alternation
meta <- removeAlternation(meta)
meta

# Current alternation
getAlternation(meta)
```

## Simplicity
```{r}
# Simple display of 10 biggest centers
applySimplicity(meta, n=10)
```

# Creating Order
```{r}
# For ordering vertex membership and sizing form a basis
getElements(meta)[ ,c('name', 'membership', 'size')]

# Analysis graph before applying order creation transformations
meta

# Try Scaling transformation
doScaling(meta, scaling=3)

# Average number of attributes
vl <- getElements(meta)[ ,c('name', 'membership', 'type')]
lapply(unique(vl$membership), function(m) {
  nent <- nrow(vl[vl$membership==m & vl$type=='entity', ])
  nattr <- nrow(vl[vl$membership==m & vl$type=='attribute', ])
  print(paste(m, 'mean number of attributes:', nattr/nent))}) -> NUL

# Try Symmetry transformation
doSymmetry(meta)

# Initiate Gradient transformation from SEQUENCE entity
meta <- doGradients(meta, 'SEQUENCE')
meta
```

# Highlighting
```{r}
# Vertex colouring by confuses highlighting  
meta <- removePartitioning2(meta)

# Highlight link attributes after applying alternation
meta <- applyAlternation(meta)
ida <- grep('>id|idx|step', getElements(meta)$name, value=TRUE)
meta <- applyHighlight(meta, ida)
meta

```

# Dynamics
*TODO: Archive and remove*
```{r}
# Facilitate reproducibility
set.seed(3)

# Generate sequences of 9 steps
n <- 9
steps <- 1:n

# Simulate the assembly sequence
asm <- unlist(lapply(steps, function(x) {
  rep(x, x + 1 + abs(rnorm(1, 0, 2)))
}))
s <- data.frame(cbind(type=rep('assembly', length(asm)), count=asm))

# Simulate the differentiation sequence
dif <- unlist(lapply(steps, function(x) {
  rep(x,  n * (n - x + abs(rnorm(1, 0, 2))))
}))
s <- rbind(s, cbind(type=rep('differentiation', length(dif)), count=dif))

# Output using ggplot2 graphics system
library(ggplot2)

col <-'darkblue'
lt <- 'dashed'
ckpt <- c('baseline', 'checkpoint 1', 'checkpoint 2')

# Build the barplot
ggplot(s, aes(x=count, fill=type)) + stat_count(width=0.8, position='dodge') +
  labs(x='steps', y='number of centers') + theme_grey(base_size=16) +
  theme(legend.position="top", legend.text=element_text(size=16)) +

  # Add checkpoints
  geom_vline(aes(xintercept=0.5), color=col, linetype=lt, size=1) +
  geom_text(aes(x=0.5, label=ckpt[1], y=100), hjust=-0.1, color=col, size=5) +
  geom_vline(aes(xintercept=3.5), color=col, linetype=lt, size=1) +
  geom_text(aes(x=3.5, label=ckpt[2], y=100), hjust=-0.1, color=col, size=5) +
  geom_vline(aes(xintercept=5.5), color=col, linetype=lt, size=1) +
  geom_text(aes(x=5.5, label=ckpt[3], y=100), hjust=-0.1, color=col, size=5)
```
